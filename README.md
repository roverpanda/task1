# Task 1: Data Pipeline â€“ CodTech Internship

## ğŸ“Œ Tools Used
- Python, Pandas, Scikit-learn
- Dataset: Titanic (binary classification)

## ğŸ§ª Steps Performed
1. Data Cleaning
2. Feature Engineering
3. Numeric and Categorical Pipelines
4. Train-test split
5. Saved cleaned data as CSVs

## ğŸš€ Output
All files saved as `.csv` and pipeline tested for accuracy.

## ğŸ”— Dataset
[Titanic Dataset](https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv)


